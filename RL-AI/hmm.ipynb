{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:11:22.778536Z",
     "start_time": "2018-12-20T17:11:22.728373Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:11:24.224364Z",
     "start_time": "2018-12-20T17:11:24.209091Z"
    }
   },
   "outputs": [],
   "source": [
    "bound = 0.005\n",
    "# Go from bid -> utility\n",
    "def get_utility(bid, pref):\n",
    "    util = 0\n",
    "    issuelist = list(pref.keys())\n",
    "    for issueindex, issue in enumerate(issuelist):\n",
    "        # values of issue in given bid\n",
    "        value = pref[issue][bid[issueindex]]\n",
    "        # weight of issue in given bid\n",
    "        weight = pref[issue]['weight']\n",
    "        util += weight*value\n",
    "    return util\n",
    "\n",
    "# Utility change to discrete move type\n",
    "def delta_mapping(delta_util):\n",
    "    if (abs(delta_util[0]) <= bound and abs(delta_util[1]) <= bound):\n",
    "        return 'silent'\n",
    "    if (abs(delta_util[0]) <= bound and delta_util[1]) > bound:\n",
    "        return 'nice'\n",
    "    if (delta_util[0] <= 0 and delta_util[1] <= 0):\n",
    "        return 'unfortunate'\n",
    "    if (delta_util[0] > 0 and delta_util[1] <= 0):\n",
    "        return 'selfish'\n",
    "    if (delta_util[0] > 0 and delta_util[1] > 0):\n",
    "        return 'fortunate'\n",
    "    if (delta_util[0] <= 0 and delta_util[1] > 0):\n",
    "        return 'concession'\n",
    "    print(delta_util)\n",
    "\n",
    "# List of bids to list of discrete moves\n",
    "def discritized_mapping(agent_bids):\n",
    "    mapped_utils_discrete = []\n",
    "    prev_utils = agent_bids[0]\n",
    "    for new_utils in agent_bids[1:]:\n",
    "        delta_util1 = new_utils[0] - prev_utils[0]\n",
    "        delta_util2 = new_utils[1] - prev_utils[1]\n",
    "        delta_util = (delta_util1, delta_util2)\n",
    "        mapped_utils_discrete.append(delta_mapping(delta_util))\n",
    "        prev_utils = new_utils\n",
    "    return mapped_utils_discrete\n",
    "        \n",
    "    \n",
    "def retrieve_all_agents_bids(train):\n",
    "    # Useful structures\n",
    "    all_issues = train['issues']\n",
    "    pref1 = train['Utility1']\n",
    "    pref2 = train['Utility2']\n",
    "    all_bids = train['bids']\n",
    "\n",
    "    mapped_utils_a1 = []\n",
    "    mapped_utils_a2 = []\n",
    "\n",
    "    # Parse utility values of bids\n",
    "    for bid in all_bids:\n",
    "        r = bid['round']\n",
    "#         print(bid)\n",
    "        # stop if the negotiation session has ended\n",
    "        if 'agent1' in bid:\n",
    "            bid_agent1 = bid['agent1'].split(',')\n",
    "            u1_b1 = get_utility(bid_agent1, pref1)\n",
    "            u2_b1 = get_utility(bid_agent1, pref2)\n",
    "            # Save the bid -> utility mapping\n",
    "            mapped_utils_a1.append([u1_b1, u2_b1, int(r)])\n",
    "        if 'agent2' in bid:\n",
    "            bid_agent2 = bid['agent2'].split(',')\n",
    "            u1_b2 = get_utility(bid_agent2, pref1)\n",
    "            u2_b2 = get_utility(bid_agent2, pref2)\n",
    "            mapped_utils_a2.append([u2_b2, u1_b2, int(r)])\n",
    "\n",
    "\n",
    "    agent1_bids = [mapped_utils_a1[i][0:2] for i in range(len(mapped_utils_a1))]\n",
    "    agent2_bids = [mapped_utils_a2[i][0:2] for i in range(len(mapped_utils_a2))]\n",
    "\n",
    "    # Discritize bidspace\n",
    "    agent1_bids_discrete = discritized_mapping(agent1_bids)\n",
    "    agent2_bids_discrete = discritized_mapping(agent2_bids)\n",
    "    \n",
    "    return (agent1_bids_discrete, agent2_bids_discrete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sensor model 1: Simple agent move as possible evidences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:28:34.874241Z",
     "start_time": "2018-12-20T17:28:34.847012Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hardheaded': 0, 'random': 1, 'conceder': 2, 'tft': 3}\n",
      "{'concession': 0, 'fortunate': 1, 'nice': 2, 'selfish': 3, 'silent': 4, 'unfortunate': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.04, 0.  , 0.02, 0.  , 0.9 , 0.04],\n",
       "       [0.42, 0.11, 0.01, 0.34, 0.  , 0.12],\n",
       "       [0.08, 0.  , 0.22, 0.  , 0.4 , 0.29],\n",
       "       [0.1 , 0.01, 0.08, 0.03, 0.62, 0.16]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='train/'\n",
    "\n",
    "train_files = os.listdir(path)\n",
    "agent_count_mapping = {}\n",
    "for t in train_files:\n",
    "    train = json.load(open(os.path.join(path, t)))\n",
    "    a1_name, a2_name = re.split(r'[^A-Za-z]+', t.strip('.json'))[0:2]\n",
    "    a1_bids, a2_bids = retrieve_all_agents_bids(train)\n",
    "    if a1_name not in agent_count_mapping:\n",
    "        agent_count_mapping[a1_name] = []\n",
    "    if a2_name not in agent_count_mapping:\n",
    "        agent_count_mapping[a2_name] = []\n",
    "    agent_count_mapping[a1_name] = agent_count_mapping[a1_name] + a1_bids\n",
    "    agent_count_mapping[a2_name] = agent_count_mapping[a2_name] + a2_bids\n",
    "\n",
    "# Start constructing the model.\n",
    "sensor_model = {}\n",
    "for k, v in agent_count_mapping.items():\n",
    "    cnt_bids = Counter(v)\n",
    "    total = len(v)\n",
    "    for key in cnt_bids:\n",
    "        cnt_bids[key] /= total\n",
    "    sensor_model[k] = dict(cnt_bids)\n",
    "    \n",
    "possible_moves = ['silent', 'concession', 'unfortunate', 'nice', 'fortunate', 'selfish']\n",
    "\n",
    "for k, moves in sensor_model.items():\n",
    "    for pm in possible_moves:\n",
    "        if pm not in moves:\n",
    "            moves[pm] = 0.0\n",
    "    sensor_model[k] = np.array(list(dict(OrderedDict(sorted(moves.items()))).values()))\n",
    "\n",
    "evidence_index = {k: v for v, k in enumerate(sorted(possible_moves))}\n",
    "state_index = {k: v for v, k in enumerate(list(sensor_model.keys()))}\n",
    "sensor_model_simple = np.array(list(sensor_model.values()))\n",
    "\n",
    "# Verification prints.\n",
    "print(state_index)\n",
    "print(evidence_index)\n",
    "sensor_model_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sensor model 2: Combination of agent move and opponent move as evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:32:31.655786Z",
     "start_time": "2018-12-20T17:32:31.626342Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hardheaded': 0, 'random': 1, 'conceder': 2, 'tft': 3}\n",
      "{'concessionconcession': 0, 'concessionfortunate': 1, 'concessionnice': 2, 'concessionselfish': 3, 'concessionsilent': 4, 'concessionunfortunate': 5, 'fortunateconcession': 6, 'fortunatefortunate': 7, 'fortunatenice': 8, 'fortunateselfish': 9, 'fortunatesilent': 10, 'fortunateunfortunate': 11, 'niceconcession': 12, 'nicefortunate': 13, 'nicenice': 14, 'niceselfish': 15, 'nicesilent': 16, 'niceunfortunate': 17, 'selfishconcession': 18, 'selfishfortunate': 19, 'selfishnice': 20, 'selfishselfish': 21, 'selfishsilent': 22, 'selfishunfortunate': 23, 'silentconcession': 24, 'silentfortunate': 25, 'silentnice': 26, 'silentselfish': 27, 'silentsilent': 28, 'silentunfortunate': 29, 'unfortunateconcession': 30, 'unfortunatefortunate': 31, 'unfortunatenice': 32, 'unfortunateselfish': 33, 'unfortunatesilent': 34, 'unfortunateunfortunate': 35}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01, 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.09, 0.01, 0.07, 0.05, 0.57, 0.11, 0.02, 0.  , 0.01,\n",
       "        0.  , 0.  , 0.02],\n",
       "       [0.15, 0.02, 0.02, 0.05, 0.12, 0.06, 0.02, 0.  , 0.  , 0.03, 0.03,\n",
       "        0.02, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.04, 0.02, 0.07,\n",
       "        0.13, 0.03, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.01, 0.  ,\n",
       "        0.02, 0.03, 0.04],\n",
       "       [0.01, 0.  , 0.  , 0.01, 0.04, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.02, 0.  , 0.05, 0.01, 0.1 , 0.05, 0.  , 0.  , 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.03, 0.  , 0.05, 0.01, 0.24, 0.07, 0.03, 0.01, 0.04,\n",
       "        0.01, 0.14, 0.07],\n",
       "       [0.05, 0.  , 0.01, 0.  , 0.  , 0.04, 0.  , 0.  , 0.  , 0.01, 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.04, 0.  , 0.01, 0.02, 0.  , 0.01, 0.  , 0.02,\n",
       "        0.  , 0.  , 0.01, 0.  , 0.02, 0.01, 0.56, 0.03, 0.03, 0.  , 0.05,\n",
       "        0.  , 0.01, 0.07]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='train/'\n",
    "\n",
    "train_files = os.listdir(path)\n",
    "agent_count_mapping = {}\n",
    "for t in train_files:\n",
    "    train = json.load(open(os.path.join(path, t)))\n",
    "    a1_name, a2_name = re.split(r'[^A-Za-z]+', t.strip('.json'))[0:2]\n",
    "    a1_bids, a2_bids = retrieve_all_agents_bids(train)\n",
    "    \n",
    "    if a1_name not in agent_count_mapping:\n",
    "        agent_count_mapping[a1_name] = []\n",
    "    if a2_name not in agent_count_mapping:\n",
    "        agent_count_mapping[a2_name] = []\n",
    "        \n",
    "    a1_com = [a1_bids[i] + a2_bids[i] for i in range(min(len(a1_bids), len(a2_bids)))]\n",
    "    a2_com = [a2_bids[i] + a1_bids[i] for i in range(min(len(a1_bids), len(a2_bids)))]\n",
    "    \n",
    "    agent_count_mapping[a1_name] = agent_count_mapping[a1_name] + a1_com \n",
    "    agent_count_mapping[a2_name] = agent_count_mapping[a2_name] + a2_com \n",
    "agent_count_mapping\n",
    "\n",
    "# Start constructing the model.\n",
    "sensor_model = {}\n",
    "for k, v in agent_count_mapping.items():\n",
    "    cnt_bids = Counter(v)\n",
    "    total = len(v)\n",
    "    for key in cnt_bids:\n",
    "        cnt_bids[key] /= total\n",
    "    sensor_model[k] = dict(cnt_bids)\n",
    "    \n",
    "pm = ['silent', 'concession', 'unfortunate', 'nice', 'fortunate', 'selfish']\n",
    "possible_moves = []\n",
    "\n",
    "for m1 in pm:\n",
    "    for m2 in pm:\n",
    "        possible_moves.append(m1 + m2)\n",
    "\n",
    "for k, moves in sensor_model.items():\n",
    "    for pm in possible_moves:\n",
    "        if pm not in moves:\n",
    "            moves[pm] = 0.0\n",
    "    sensor_model[k] = np.array(list(dict(OrderedDict(sorted(moves.items()))).values()))\n",
    "\n",
    "evidence_index = {k: v for v, k in enumerate(sorted(possible_moves))}\n",
    "state_index = {k: v for v, k in enumerate(list(sensor_model.keys()))}\n",
    "\n",
    "sensor_model= np.array(list(sensor_model.values()))\n",
    "print(state_index)\n",
    "print(evidence_index)\n",
    "sensor_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:11:28.132372Z",
     "start_time": "2018-12-20T17:11:28.122808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_transition = np.identity(len(state_index), dtype=float)\n",
    "state_transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:11:29.471926Z",
     "start_time": "2018-12-20T17:11:29.467883Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_agent(bids):\n",
    "    Bt = np.ones(4)*0.25\n",
    "    for t, bt in enumerate(bids):\n",
    "        sm1 = sensor_model[:, evidence_index[bt]]\n",
    "        stm1 = np.dot(state_transition, Bt)\n",
    "        Bt = np.multiply(sm1, stm1)\n",
    "        Bt = Bt/sum(Bt)\n",
    "    return Bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:22:16.669285Z",
     "start_time": "2018-12-20T17:22:16.632196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: tft, labels: hardheaded, file: hardheaded_tft1.json\n",
      "prediction: tft, labels: hardheaded, file: hardheaded_tft2.json\n"
     ]
    }
   ],
   "source": [
    "path='train/'\n",
    "\n",
    "train_files = os.listdir(path)\n",
    "agent_count_mapping = {}\n",
    "labels_keys = list(state_index.keys())\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "for t in train_files:\n",
    "    train = json.load(open(os.path.join(path, t)))\n",
    "    a1_name, a2_name = re.split(r'[^A-Za-z]+', t.strip('.json'))[0:2]\n",
    "    a1_bids, a2_bids = retrieve_all_agents_bids(train)\n",
    "    labels.append(a1_name)\n",
    "    labels.append(a2_name)\n",
    "    \n",
    "    a1_com = [a1_bids[i] + a2_bids[i] for i in range(min(len(a1_bids), len(a2_bids)))]\n",
    "    a2_com = [a2_bids[i] + a1_bids[i] for i in range(min(len(a1_bids), len(a2_bids)))]\n",
    "    \n",
    "    p1 = predict_agent(a1_com)\n",
    "    p2 = predict_agent(a2_com)\n",
    "    \n",
    "    preds.append(labels_keys[np.argmax(p1)])\n",
    "    preds.append(labels_keys[np.argmax(p2)])\n",
    "    \n",
    "    if preds[-1] != labels[-1]: \n",
    "        print(\"prediction: {}, labels: {}, file: {}\".format(preds[-1], labels[-1], t))\n",
    "        \n",
    "    if preds[-2] != labels[-2]: \n",
    "        print(\"prediction: {}, labels: {}, file: {}\".format(preds[-2], labels[-2], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T17:11:32.792104Z",
     "start_time": "2018-12-20T17:11:32.787684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [labels[x] == preds[x] for x in range(len(labels))]\n",
    "# for i i\n",
    "sum(c)/float(len(labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
